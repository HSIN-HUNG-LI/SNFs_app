{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895e111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 6870 rows\n",
      "Filtered dataset size: 56 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_snf_list(txt_path):\n",
    "    \"\"\"\n",
    "    Load SNF IDs from a text file. The text file should contain\n",
    "    comma-separated SNF names (e.g., LJ1099, LJ1109,...).\n",
    "    Returns a list of SNF names.\n",
    "    \"\"\"\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    # Split by comma and strip whitespace\n",
    "    return [name.strip() for name in content.split(\",\") if name.strip()]\n",
    "\n",
    "\n",
    "def filter_dataset_by_snf(df, snf_list):\n",
    "    \"\"\"\n",
    "    Filter the input DataFrame and return only rows where the 'Name' column\n",
    "    matches one of the SNF names in the list.\n",
    "    \"\"\"\n",
    "    return df[df[\"Name\"].isin(snf_list)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define file paths\n",
    "    csv_path = \"data/all_stdh_dataset.csv\"\n",
    "    snf_txt_path = \"data/TSC01_SNFs.txt\"\n",
    "\n",
    "    # Load dataset and SNF list\n",
    "    df = pd.read_csv(csv_path)\n",
    "    snf_list = load_snf_list(snf_txt_path)\n",
    "\n",
    "    # Filter dataset\n",
    "    filtered_df = filter_dataset_by_snf(df, snf_list)\n",
    "\n",
    "    # Optional: print result summary\n",
    "    print(f\"Original dataset size: {len(df)} rows\")\n",
    "    print(f\"Filtered dataset size: {len(filtered_df)} rows\")\n",
    "\n",
    "    # Save filtered result if needed\n",
    "    filtered_df.to_csv(\"all_stdh_dataset_tsc01.csv\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531882ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1A0016', '1A0026', '1A0009', '1A0003', '1A0066', '1A0098', '1A0319', '1A0103', '1A0198', '1A0329', '1A0407', '1A0028', '1A0272', '1A0119', '1B0548', '1B0506', '1B0513', '1A0238', '1A0248', '1A0007', '1A0406', '1A0089', '1B0541', '1B0501', '1B0547', '1A0311', '1A0273', '1A0012', '1A0013', '1A0338', '1A0088', '1B0430', '1B0475', '1B0516', '1A0306', '1A0190', '1A0015', '1A0014', '1A0072', '1B0500', '1B0514', '1B0542', '1A0297', '1A0361', '1A0360', '1A0138', '1A0149', '1A0373', '1A0385', '1A0218', '1A0129', '1A0010', '1A0068', '1A0109', '1A0011', '1A0018']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/all_stdh_dataset.csv')\n",
    "\n",
    "with open('TSC01_SNFs.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "names = [n.strip() for n in text.replace(',', '\\n').splitlines() if n.strip()]\n",
    "\n",
    "\n",
    "mapping = df.set_index('Name')['SNF_id']\n",
    "snf_ids = mapping.loc[names].tolist()\n",
    "\n",
    "print(snf_ids)\n",
    "with open('TSC01_SNF_id.txt', 'w') as f:\n",
    "    f.write(', '.join(snf_ids))\n",
    "pd.DataFrame({'SNF_id': snf_ids}).to_csv('TSC01_SNF_id.csv', index=False, header=False)\n",
    "\n",
    "\n",
    "\n",
    "# End "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bb58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'Type' values:\n",
      "['GE88-1' 'GE88-2'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().resolve().parents[1]\n",
    "data_file = project_root / \"data\" / \"test_files\" / \"all_stdh_dataset_tsc01.csv\"\n",
    "df = pd.read_csv(data_file)\n",
    "type_map = {\n",
    "    \"GE88-1\": \"TypeA\",\n",
    "    \"GE88-2\": \"TypeB\",\n",
    "    \"Atrium10\": \"TypeC\",\n",
    "    \"SPC88\": \"TypeD\",\n",
    "    \"GE9B\": \"TypeE\"\n",
    "}\n",
    "\n",
    "print(\"Original 'Type' values:\")\n",
    "print(df[\"Type\"].unique(), \"\\n\")\n",
    "\n",
    "unknown = set(df[\"Type\"].unique()) - set(type_map.keys())\n",
    "if unknown:\n",
    "    print(f\"‚ùó Found unmapped Type values: {unknown}\\n\")\n",
    "    print(\"Rows with unmapped Type values:\")\n",
    "    print(df[df[\"Type\"].isin(unknown)])\n",
    "    raise ValueError(f\"Unmapped Type values found: {unknown}\")\n",
    "\n",
    "df[\"Type\"] = df[\"Type\"].replace(type_map)\n",
    "\n",
    "df.to_csv(data_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
